{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe970b78-9307-433e-ac09-95b1bc25c955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c74e5ae-43b4-416c-9dce-85c6760018e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e4fd307-baa1-484c-a29f-7c04e0772fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54997a95-7c8e-43fd-bf95-db3c555265f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbe773a2-41a2-46bf-a66c-5108aff25707",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data.data, data.target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b53469f-81ec-49c4-85c8-bc69f87c8d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MedInc',\n",
       " 'HouseAge',\n",
       " 'AveRooms',\n",
       " 'AveBedrms',\n",
       " 'Population',\n",
       " 'AveOccup',\n",
       " 'Latitude',\n",
       " 'Longitude']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1516efc-a930-4136-a945-a25c2a7bdf90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20640, 8), (20640,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84e5ab72-947a-4115-9929-7e0a86ebf9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   8.3252    ,   41.        ,    6.98412698,    1.02380952,\n",
       "        322.        ,    2.55555556,   37.88      , -122.23      ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f7c89a8-25a1-4ccb-8024-b4395c581974",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cdbbeec-932c-4b61-a8df-354501c3027b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.reshape(-1,1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a310e3aa-f9cd-485b-b61a-fc62f8ff7baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.random.randn(X.shape[1], 1) * 0.01\n",
    "bias = np.zeros((1,1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12bd59e6-3ab9-47e2-b4eb-f6c9d8cc4082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.00624857],\n",
       "        [ 0.00461895],\n",
       "        [ 0.01858074],\n",
       "        [-0.00168651],\n",
       "        [ 0.00860636],\n",
       "        [ 0.01038476],\n",
       "        [-0.01024801],\n",
       "        [-0.00038599]]),\n",
       " array([[0.]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e80600f5-c684-40e8-a102-5a5325cbcbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = X.shape[0]\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5628f2d-5849-43f6-ae77-a17d99b16712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, (20640, 8), (8, 1), (1, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, X.shape, weights.shape, bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae067f99-557e-4d6d-9d92-f73d19b13691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.590985746380969\n",
      "4.691300657474584\n",
      "3.95576373391659\n",
      "3.354173533773975\n",
      "2.8619414715895686\n",
      "2.459032208903183\n",
      "2.1291090629233493\n",
      "1.8588432644327102\n",
      "1.6373546065353484\n",
      "1.4557577667771215\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    y_pred = np.dot(X , weights) + bias\n",
    "    loss = np.mean((y_pred - y)**2)\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(loss)\n",
    "\n",
    "    residual = y_pred - y\n",
    "    \n",
    "    dw = (1/m) *  np.dot(X.T, residual)\n",
    "    db = np.sum(residual) / m   # FIXED\n",
    "    \n",
    "    weights -= learning_rate * dw\n",
    "    bias -= learning_rate * db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0ca2a7f-1906-40c3-9e2e-6ac5860d1953",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e5c37d6-aaaa-44a2-a1a9-be862ff1d620",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c6ddcc1-1049-4ed4-96c8-b9a031399025",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64ce0957-d324-440a-8e43-75d3ca474a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y= data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9df39f8-6fd3-4ea6-8a8c-efc82882a53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b78f883-905b-454b-9a35-3892149bb597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 30), (569,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7122b77-df7a-4a7f-9080-50fb77e207d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (X - X.mean(axis = 0)) / X.std(axis =0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "035ac494-31af-4210-97f6-73fc67549d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "860025e6-9a3b-49f7-81b2-c2e939f8daa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.09706398, -2.07333501,  1.26993369,  0.9843749 ,  1.56846633,\n",
       "         3.28351467,  2.65287398,  2.53247522,  2.21751501,  2.25574689,\n",
       "         2.48973393, -0.56526506,  2.83303087,  2.48757756, -0.21400165,\n",
       "         1.31686157,  0.72402616,  0.66081994,  1.14875667,  0.90708308,\n",
       "         1.88668963, -1.35929347,  2.30360062,  2.00123749,  1.30768627,\n",
       "         2.61666502,  2.10952635,  2.29607613,  2.75062224,  1.93701461]),\n",
       " array([0]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f35db284-ce63-4c5b-b7e7-c07aff86032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.random.randn(X.shape[1],1) * 0.01\n",
    "bias = np.zeros((1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19e63974-d5e3-442c-a9f6-5a45e37224b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30, 1), (569, 30), (1, 1), (569, 1))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape, X.shape, bias.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c56791fb-fc9f-4f46-b8c1-23a3637b5112",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = X.shape[0]\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a37b8b4-1641-437d-b1c7-b9cbb46d6645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_loss(y_pred, y):\n",
    "    loss =  - y * np.log(y_pred) - (1-y) * np.log(1-y_pred)\n",
    "    return np.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82536f96-9655-4ac3-aa76-066ca6a5437e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.7017529746007928\n",
      "accuracy 0.29701230228471004\n",
      "loss 0.5489705450817699\n",
      "accuracy 0.929701230228471\n",
      "loss 0.4608837957763806\n",
      "accuracy 0.9349736379613357\n",
      "loss 0.40388442107783795\n",
      "accuracy 0.9367311072056239\n",
      "loss 0.3637344122044971\n",
      "accuracy 0.9402460456942003\n",
      "loss 0.333718970191316\n",
      "accuracy 0.9402460456942003\n",
      "loss 0.31028701466753816\n",
      "accuracy 0.9420035149384886\n",
      "loss 0.29138654030146244\n",
      "accuracy 0.9437609841827768\n",
      "loss 0.2757483157231162\n",
      "accuracy 0.9472759226713533\n",
      "loss 0.26254414364336714\n",
      "accuracy 0.9507908611599297\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    a = np.dot(X, weights) + bias\n",
    "    y_pred = 1 / ( 1 + np.exp(-a))\n",
    "\n",
    "    loss = binary_loss(y_pred, y)\n",
    "    if i % 100 == 0:\n",
    "        print(\"loss\", loss)\n",
    "        accuracy = (y_pred >= .5) == y\n",
    "        print(\"accuracy\", np.sum(accuracy)/m)\n",
    "    \n",
    "    \n",
    "    error = y_pred - y\n",
    "\n",
    "    dw = (1/m) * np.dot(X.T, error)\n",
    "    db = (1/m) * np.sum(error)\n",
    "\n",
    "    weights -= learning_rate * dw\n",
    "    bias -= learning_rate * db\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d3a30fb-659e-4575-9575-49c8175a93d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d95d105-0871-439a-81f7-1449fad51859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "077abe76-c652-4dfc-9f4f-11d339b68833",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d718aff2-0486-444f-84ea-1ccc880f62f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "42a54279-b437-48b7-a7c9-3c5accabab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (X - X.mean(axis=0))/ X.std(axis=0)\n",
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3362a678-eb19-4ce6-b750-cbc1b378e6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20640, 8), (20640, 1))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "291d1db8-5a26-4c00-a9d6-fab490c8a3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.34476576,  0.98214266,  0.62855945, -0.15375759, -0.9744286 ,\n",
       "        -0.04959654,  1.05254828, -1.32783522]),\n",
       " array([4.526]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8fb060a2-f9d4-49c3-bc16-84e18696d4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = X.shape[0]\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "20bd4756-dd24-4c5a-a20c-34e0a932eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = X.shape[1]\n",
    "\n",
    "layers = [12,8,4,1]\n",
    "weights = {}\n",
    "bias = {}\n",
    "\n",
    "for i in range(len(layers)):\n",
    "    weights[f\"W{i}\"] = np.random.randn(layers[i], prev)\n",
    "    bias[f\"b{i}\"] = np.zeros((layers[i], 1))\n",
    "    prev = layers[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f384bf3a-a1dc-4dea-a837-c75171b43a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce439043-7af0-4ba8-a9f1-25575aa5bd15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bf94c24c-79cb-4c5a-a4a7-aff815349bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'W0': array([[ 3.11831971, -0.6872158 ,  1.34358889, -0.97405175, -2.79606643,\n",
       "          -0.53458966,  0.32873042, -0.0308331 ],\n",
       "         [ 2.09228515, -0.58423135, -3.54251035, -0.96537798, -2.43242561,\n",
       "           0.39983572, -0.29087657,  0.83912278],\n",
       "         [ 0.25906262,  1.03533333, -1.18466681,  0.43616851,  0.88009366,\n",
       "          -2.3724459 , -0.24306021,  0.59118237],\n",
       "         [ 1.53861388, -0.31074631,  0.68048811, -0.52936416, -0.74551814,\n",
       "           1.46277657,  1.33991791, -0.10841388],\n",
       "         [ 0.21843953, -0.30272251,  0.75045008,  0.17495442, -0.33806442,\n",
       "          -1.29877635, -0.31687994, -2.05784913],\n",
       "         [ 1.80765351, -2.51661465,  0.85334123,  0.92841523,  2.16249836,\n",
       "          -0.84373844, -0.67131784, -0.71227349],\n",
       "         [-0.0233813 ,  1.19492663,  1.973216  , -0.7231188 , -0.3395483 ,\n",
       "           0.48577486, -0.10932921,  0.40418105],\n",
       "         [ 0.92407899,  0.26461296,  1.20279506,  1.14331123,  0.02984194,\n",
       "           0.0112738 , -1.29715938, -1.17472573],\n",
       "         [ 0.86360152,  0.13840101, -0.6002475 ,  0.07970785, -1.2942831 ,\n",
       "           0.57209537, -0.93859005,  1.31858717],\n",
       "         [ 1.64971744, -0.71531251,  0.12149056, -0.40586363,  0.71364115,\n",
       "           1.72291879,  0.21944231,  0.3817284 ],\n",
       "         [ 2.18220885, -1.60347382,  0.6962591 ,  0.69804478, -0.60411209,\n",
       "          -0.62764626, -0.43514611,  1.96670428],\n",
       "         [ 0.62746624,  0.67846274,  0.45870793,  2.44789118,  1.27823678,\n",
       "          -0.18446759, -0.00664959, -1.40825908]]),\n",
       "  'W1': array([[ 0.82742589, -0.34707619,  0.1107951 ,  1.79269618, -3.10067985,\n",
       "          -0.23894155, -0.8840147 , -1.10315061,  1.04785711, -0.31118469,\n",
       "          -0.615132  ,  0.69299753],\n",
       "         [-0.1761272 ,  0.37682154,  1.89203785, -0.45246451, -0.6617018 ,\n",
       "           2.52020655,  0.37901937, -1.10350727,  0.10150855, -0.62566868,\n",
       "           0.53588086, -1.25170767],\n",
       "         [ 0.22940857, -0.06185865, -0.97701861,  0.33892852,  0.1524884 ,\n",
       "           1.14386691,  2.15852136, -0.28763041,  1.46249999,  1.12837641,\n",
       "          -0.32930718,  0.59433302],\n",
       "         [-0.15672309, -0.24942352, -0.2876478 ,  3.34391037,  0.13445642,\n",
       "           0.66072402, -0.66585518,  0.44883065, -2.19966371,  0.10689472,\n",
       "           0.69960266, -0.26151985],\n",
       "         [-1.65889674,  0.40135895, -0.19619544,  0.09840616,  0.02782433,\n",
       "           1.20452291, -1.42116296,  0.68563657, -0.27353992, -0.02749043,\n",
       "           0.3373677 ,  0.97585179],\n",
       "         [-1.4853584 ,  1.88119562, -1.20066215,  0.29543932, -0.33689964,\n",
       "           0.9608835 , -1.64916786,  0.46345163,  0.06745336, -0.23615932,\n",
       "          -0.49033951,  0.38833037],\n",
       "         [ 0.02475203, -1.16323742, -2.34917489, -1.31453814, -1.7398188 ,\n",
       "          -0.24980872,  1.004478  , -1.22410458, -0.50215621,  0.92277316,\n",
       "           0.68344406, -1.20473088],\n",
       "         [-2.52781968, -0.44321187,  1.60219499,  0.20678275,  0.07603154,\n",
       "           0.55773028,  0.2377012 ,  0.1390282 ,  0.50976353, -1.37142303,\n",
       "           0.0623977 ,  0.69376692]]),\n",
       "  'W2': array([[-0.56809725, -0.13489891, -0.5673983 , -1.47423858,  0.30177547,\n",
       "          -0.32581646, -0.65778726,  0.50240798],\n",
       "         [-1.62464036, -0.33980701,  0.16458472, -0.6229728 , -1.09768444,\n",
       "           1.05387584,  0.88704757, -0.17883172],\n",
       "         [ 0.91790443, -0.21609511,  0.88477958,  1.36542641,  1.33621464,\n",
       "          -1.71267524,  0.85517444,  0.97574552],\n",
       "         [-1.86113172,  0.79970008,  1.71176361,  0.4752878 , -0.94509586,\n",
       "          -2.42290337,  0.76609044, -0.47824615]]),\n",
       "  'W3': array([[-0.52896397,  3.38610988,  0.90286055, -0.42292224]])},\n",
       " {'b0': array([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]),\n",
       "  'b1': array([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]),\n",
       "  'b2': array([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]),\n",
       "  'b3': array([[0.]])})"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bb5f29fc-e14f-412e-a163-2c1bbd4ecaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "def sigmoid(x):\n",
    "    \n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6b726a23-a488-4814-b959-794bfa47f566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X):\n",
    "    m = X.shape[1]\n",
    "    cache = {}\n",
    "    cache[f\"A{-1}\"] = X\n",
    "    A = X\n",
    "\n",
    "    for i in range(len(layers)-1):\n",
    "        Z = np.dot(weights[f\"W{i}\"], A) + bias[f\"b{i}\"]\n",
    "        A = relu(Z)\n",
    "\n",
    "        \n",
    "        cache[f\"Z{i}\"] = Z\n",
    "        cache[f\"A{i}\"] = A\n",
    "\n",
    "    l = len(layers) - 1\n",
    "\n",
    "    Z = np.dot( weights[f\"W{l}\"], A) + bias[f\"b{l}\"]\n",
    "    A = sigmoid(Z)\n",
    "    cache[f\"Z{l}\"] = Z\n",
    "    cache[f\"A{l}\"] = A\n",
    "    return A, cache\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a9fc6123-eead-44de-89fb-080cc18f92a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(cache, y):\n",
    "    grad = {}\n",
    "    m = y.shape[1]\n",
    "    l = len(layers) - 1\n",
    "    dZ = cache[f\"A{l}\"] - y\n",
    "    grad[f\"dW{l}\"] = (1/m) * dZ.dot(cache[f\"A{l-1}\"].T)\n",
    "    grad[f\"db{l}\"] = (1/m) * np.sum(dZ, axis =1 , keepdims = True)\n",
    "    dA = np.dot(weights[f\"W{l}\"].T, dZ)\n",
    "\n",
    "    for i in reversed(range(l)):\n",
    "        dZ = dA * relu_derivative(cache[f\"Z{i}\"])\n",
    "        grad[f\"dW{i}\"] = (1/m) * dZ.dot(cache[f\"A{i-1}\"].T)\n",
    "        grad[f\"db{i}\"] = (1/m) * np.sum(dZ, axis = 1, keepdims = True)\n",
    "        dA = np.dot(weights[f\"W{i}\"].T, dZ)\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a2c82ea4-824f-4723-a03b-f05791efa8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updated_weights(grad):\n",
    "    learning_rate = 0.001\n",
    "    for i in range(len(layers)):\n",
    "        weights[f\"W{i}\"] -= learning_rate * grad[f\"dW{i}\"]\n",
    "        \n",
    "        bias[f\"b{i}\"] -= learning_rate * grad[f\"db{i}\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8ca5c1d8-8387-40b1-93e6-47a3ecbf3f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, cache = forward(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "28cf4d75-de5b-4d1d-97e0-d74e51e90a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = backward(cache, y.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cb522235-521b-4d79-af18-e4b44d1841ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_loss1(z, y):\n",
    "    z = np.clip(z, 1e-12, 1- 1e-12)\n",
    "    return binary_loss(z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a19c9307-1afe-4df1-b913-40c0017cf11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9.468384086545871\n",
      "-10.28343947690716\n",
      "-11.0500125427598\n",
      "-11.764267758031476\n",
      "-12.438238920557076\n",
      "-13.082570201573963\n",
      "-13.693959881233875\n",
      "-14.274542950944943\n",
      "-14.83227133881689\n",
      "-15.371034097691746\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    y_pred, cache = forward(X.T)\n",
    "    loss = binary_loss1(y_pred.T, y)\n",
    "    print(loss)\n",
    "    grads = backward(cache, y.T)\n",
    "    updated_weights(grads)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "76d067da-2dcd-4fc7-84f5-04781ab1f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormalization:\n",
    "    def __init__(self, num_features):\n",
    "        self.gamma = np.random.randn(num_features)\n",
    "        self.beta = np.zeros(num_features)\n",
    "        self.momentum= 0.9\n",
    "        self.epsilon = 1e-12\n",
    "        self.moving_mean = np.zeros(num_features)\n",
    "        self.moving_var = np.ones(num_features)\n",
    "\n",
    "    def forward(self, x, train= True):\n",
    "        if train:\n",
    "            x_mean = x.mean(axis = 0)\n",
    "            x_var = x.var(axis = 0)\n",
    "\n",
    "            x_scaled = (x - x_mean) / np.sqrt(x_var + self.epsilon)\n",
    "            x = self.gamma * x_scaled + self.beta\n",
    "            self.moving_mean = self.moving_mean * self.momentum + (1 - self.momentum) * x_mean\n",
    "            self.movinb_var = self.moving_var * self.momentum + (1 - self.momentum) * x_var\n",
    "            return x\n",
    "        else:\n",
    "            x_scaled = (x - self.moving_mean) / np.sqrt(self.moving_var + self.epsilon)\n",
    "            x = self.gamma * x_scaled + self.beta\n",
    "            return x\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f0ae3002-b252-450d-a735-1e326948130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm:\n",
    "    def __init__(self, num_layers):\n",
    "        self.gamma = np.random.randn(num_layers)\n",
    "        self.beta = np.zeros(num_layers)\n",
    "        self.epsilon = 1e-12\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_mean = np.mean(x, axis = 0, keepdims= True)\n",
    "        x_var = np.var(x, axis = 0, keepdims = True)\n",
    "\n",
    "        x_scaled = (x - x_mean)/ np.sqrt(x_var + self.epsilon)\n",
    "\n",
    "        x = self.gamma * x_scaled + self.beta\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9ffd905c-a431-44a9-888d-b03721bdf308",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randint(0, 10, size = (10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e2594746-3818-4887-b3c4-e2b6014971f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 7, 4, 4, 4],\n",
       "       [8, 8, 7, 2, 9],\n",
       "       [0, 1, 7, 7, 9],\n",
       "       [1, 1, 5, 0, 5],\n",
       "       [1, 3, 6, 4, 4],\n",
       "       [6, 5, 9, 8, 8],\n",
       "       [6, 0, 8, 4, 6],\n",
       "       [7, 7, 5, 6, 0],\n",
       "       [6, 0, 0, 4, 9],\n",
       "       [5, 0, 2, 0, 6]], dtype=int32)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "45a1fca1-83af-427d-aebd-0150e852f1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnorm = BatchNormalization(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d274f273-88e6-4b69-8dab-c0ca76711ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.43974236,  1.73412618,  0.19932357,  0.01643176,  0.01221521],\n",
       "       [ 1.25157442,  2.19047517, -0.2606539 , -0.31220353, -0.01832282],\n",
       "       [-1.45453244, -1.00396779, -0.2606539 ,  0.50938471, -0.01832282],\n",
       "       [-1.11626908, -1.00396779,  0.04599775, -0.64083882,  0.00610761],\n",
       "       [-1.11626908, -0.0912698 , -0.10732808,  0.01643176,  0.01221521],\n",
       "       [ 0.57504771,  0.82142819, -0.56730555,  0.67370235, -0.01221521],\n",
       "       [ 0.57504771, -1.46031678, -0.41397972,  0.01643176,  0.        ],\n",
       "       [ 0.91331107,  1.73412618,  0.04599775,  0.34506706,  0.03664564],\n",
       "       [ 0.57504771, -1.46031678,  0.81262686,  0.01643176, -0.01832282],\n",
       "       [ 0.23678435, -1.46031678,  0.50597522, -0.64083882,  0.        ]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnorm.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a8b35241-116b-4812-abb0-140f82d2b5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "lnorm = LayerNorm(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353c77d8-9975-44e3-ba9e-fc2a37b31635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f419b4cd-9b4f-4ec0-ba0b-daf4e2d0d8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = lnorm.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "066d90bb-a463-4d2e-a0ea-fc6446f05953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.84195611, -1.86715284,  0.1567224 ,  0.02707515, -0.87292167],\n",
       "       [-2.39633661, -2.35850885, -0.20494468, -0.51442783,  1.3093825 ],\n",
       "       [ 2.78493173,  1.08098322, -0.20494468,  0.83932961,  1.3093825 ],\n",
       "       [ 2.13727319,  1.08098322,  0.03616671, -1.0559308 , -0.43646083],\n",
       "       [ 2.13727319,  0.0982712 , -0.08438899,  0.02707515, -0.87292167],\n",
       "       [-1.10101952, -0.88444082, -0.44605607,  1.1100811 ,  0.87292167],\n",
       "       [-1.10101952,  1.57233923, -0.32550038,  0.02707515,  0.        ],\n",
       "       [-1.74867807, -1.86715284,  0.03616671,  0.56857813, -2.618765  ],\n",
       "       [-1.10101952,  1.57233923,  0.63894518,  0.02707515,  1.3093825 ],\n",
       "       [-0.45336098,  1.57233923,  0.39783379, -1.0559308 ,  0.        ]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "cb2a4946-8790-4872-bdc0-26784328ff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    def __init__(self, parameters, learning_rate = 0.001, beta1 = 0.9, beta2 = 0.99):\n",
    "        self.params = parameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.m = [np.zeros_like(m) for m in parameters]\n",
    "        self.v = [np.zeros_like(m) for m in parameters]\n",
    "        self.t = 1\n",
    "        self.epsilon = 1e-12\n",
    "\n",
    "    def step(self, grads):\n",
    "\n",
    "        for idx, grad in enumerate(grads):\n",
    "            m = self.beta1 * self.m[idx] + (1- self.beta1) * grad\n",
    "            v = self.beta2 * self.v[idx] + (1 - self.beta2) * grad ** 2\n",
    "            m = m / (1 - self.beta1 ** self.t)\n",
    "            v = v / (1 - self.beta2 ** self.t)\n",
    "\n",
    "            self.m[idx] = m\n",
    "            self.v[idx] = v\n",
    "            self.params[idx] -= learning_rate * (m / np.sqrt(v + self.epsilon))\n",
    "\n",
    "        self.t +=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "73186478-c5d4-44dc-a2ab-80bc223931c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [np.random.randn(m) for m in [12,2,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "a11b6bf5-5d97-4f0f-9f08-898f2a28dde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_c = params.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ee093f65-bfd7-480c-8f02-b625df5ef797",
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = [m * np.random.randn(1) * 0.01 for m in prams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "9754555c-3414-41d5-9aed-a31eab26dcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(prams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "08fcd7bf-760c-4894-a4c3-a826e6980402",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "34773c78-29b9-420a-830e-a64d01418b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.44002423, -1.73868727,  0.43077806, -0.77118064,  1.10888205,\n",
       "        -0.17105573, -0.52767842, -1.48297304, -0.77391791,  0.46315121,\n",
       "        -0.09043118,  0.02298037]),\n",
       " array([ 0.4310773 , -1.31845386]),\n",
       " array([-1.0001559 , -1.3860749 , -1.01459203,  0.26044208])]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "b22e06d4-557e-4c36-b258-b9417d0d4153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.11888624,  0.93871594,  1.2341828 ,  1.36895591, -0.07017109,\n",
       "        -0.3781867 ,  0.15237563,  1.07547484,  0.68693854,  0.36210822,\n",
       "        -0.68858785,  0.75941918]),\n",
       " array([-0.35653899,  0.44489863]),\n",
       " array([ 1.74649008, -0.42283103,  0.5197996 ,  0.70050476])]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb459cd-8372-4dcb-9a53-0cff477ad139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "218b4e82-cba6-4823-bf3c-07043e2880ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "\n",
    "# def mock_llm(state: MessagesState):\n",
    "#     return {\"messages\": [{\"role\": \"ai\", \"content\": \"hello world\"}]}\n",
    "\n",
    "# graph = StateGraph(MessagesState)\n",
    "# graph.add_node(mock_llm)\n",
    "# graph.add_edge(START, \"mock_llm\")\n",
    "# graph.add_edge(\"mock_llm\", END)\n",
    "# graph = graph.compile()\n",
    "\n",
    "# graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"hi!\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "a2d29096-5cd4-430c-ad5f-ca45b1caa130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "189e59d1-e10c-4ceb-814f-e0189a5e2d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "cf9fd333-983c-4423-855d-e4ce9431e62f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20640, 8), (20640,))"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "38ed14bd-5ddf-4c6f-a2da-99cd31b0ebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "2c2c8683-6016-4e83-a413-42269eb694f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "46df6e92-a555-4b37-a0b0-13c920792fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train  = torch.tensor(X_train, dtype = torch.float32)\n",
    "X_test  = torch.tensor(X_test, dtype = torch.float32)\n",
    "y_train  = torch.tensor(y_train, dtype = torch.float32)\n",
    "y_test  = torch.tensor(y_test, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "72119353-268f-4d39-936e-2d2e2090c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, in_features, out_features, hidden_dim = 32):\n",
    "        super().__init__()\n",
    "        self.layers1 = nn.Linear(in_features,hidden_dim)\n",
    "        self.layers2 = nn.Linear(hidden_dim, hidden_dim//2)\n",
    "        self.layers3 = nn.Linear(hidden_dim//2, out_features)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers1(x)\n",
    "        x = self.layers2(self.relu(x))\n",
    "        x = self.layers3(self.relu(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "859542a2-8d58-4989-9ceb-d5f0b624a4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RegressionModel(X.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "4214fad3-da0e-40e1-8ecd-771d3ce7c919",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "0396ccb4-45df-4ba1-90ff-397fa8ebe02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "5d882a7b-21c8-4316-affa-a2e6c5061035",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params =model.parameters(),lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "19b36362-31e8-40dc-8bff-aa4a8eb1c8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.607321739196777\n",
      "16.382476806640625\n",
      "30.710865020751953\n",
      "43.13301467895508\n",
      "44.281005859375\n",
      "34.7808723449707\n",
      "20.90658187866211\n",
      "10.04626750946045\n",
      "6.984131336212158\n",
      "11.414653778076172\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    model.train()\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    print(loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "fa021d05-5e07-438c-bf37-a3a862d93927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "7a00606c-0921-4b72-b624-6e685654c131",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "y = y.reshape(-1, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "eb6c12e9-b5af-4e92-89c0-ef5dcd865ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype = torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype = torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype = torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype = torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "6d6e8b53-ab87-4693-80e8-dd16ac02bc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryModel(nn.Module):\n",
    "    def __init__(self, in_features, out_features, hidden_dim=32):\n",
    "        super().__init__()\n",
    "        self.layers1 = nn.Linear(in_features = in_features, out_features = hidden_dim)\n",
    "        self.layers2 = nn.Linear(in_features = hidden_dim, out_features = hidden_dim // 2)\n",
    "        self.layers3 = nn.Linear(hidden_dim // 2, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers1(x)\n",
    "        x = self.layers2(self.relu(x))\n",
    "        x = self.layers3(self.relu(x))\n",
    "\n",
    "        return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "295267bb-fccc-4666-b2f0-8622ccdf2953",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BinaryModel(X.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "b3b43919-60c8-4f4b-a49e-8d1a473bd053",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "297aee56-3399-4d55-87de-5cf11eb2cf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "b1789569-0b8d-4604-b9fb-2d0ed70d868f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3977)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    model.train()\n",
    "\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    y_pred = model(X_test) \n",
    "    print(loss_fn(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "0c5b945e-1037-4322-8f01-2968697accf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4676])\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    y_pred = model(X_test) \n",
    "    print(torch.sigmoid(y_pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "5d4ff837-f87f-4336-a472-8583545f8a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "y = y.reshape(-1, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = .2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "81588dbc-5dc5-47a9-9ff4-4b842d58e7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype = torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype = torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype = torch.long)\n",
    "y_test = torch.tensor(y_test, dtype = torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "2edc99ac-c277-4835-8f91-dd97206b3671",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClfModel(nn.Module):\n",
    "    def __init__(self, in_features, out_features, hidden_dim=32):\n",
    "        super().__init__()\n",
    "        self.layers1 = nn.Linear(in_features = in_features, out_features = hidden_dim)\n",
    "        self.layers2 = nn.Linear(in_features = hidden_dim, out_features = hidden_dim // 2)\n",
    "        self.layers3 = nn.Linear(hidden_dim // 2, out_features)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers1(x)\n",
    "        x = self.layers2(self.relu(x))\n",
    "        x = self.layers3(self.relu(x))\n",
    "\n",
    "        return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "8db05486-db21-448a-92b1-a18eab396ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClfModel(X.shape[1], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "b2865de0-e466-4ee0-afc9-367ea81df78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "6711868e-aa96-45b1-ac65-388e94390184",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params = model.parameters(), lr= 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "a7c794b4-2665-4b12-ac79-ad480df3fa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9242, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9111, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9044, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8977, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8909, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8841, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8772, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8702, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8632, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8561, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8489, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8417, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8344, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8271, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8046, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7968, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7891, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7814, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7739, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7667, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7595, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7523, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7448, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7373, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7298, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7224, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7079, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6937, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6866, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6796, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6727, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6658, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6590, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6523, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6456, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6391, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6326, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6262, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6137, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6076, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5955, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5896, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5838, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5781, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5725, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5669, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5615, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5561, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5508, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5456, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5404, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5354, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5304, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5254, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5157, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5062, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5016, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4970, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4924, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4879, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4834, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4790, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4747, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4704, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4661, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4619, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4577, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4536, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4494, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4452, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4411, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4370, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4329, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4288, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4247, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4167, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4088, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4048, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3970, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3931, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3893, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3855, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3816, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3778, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3741, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3703, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3666, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3629, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    model.train()\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, y_train.squeeze(1))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "af239ea8-9ea1-4b2b-b31b-4ca88a668d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "c6076f4f-5e4e-4fd7-9c4c-6db308922b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "be8f7449-f557-46ea-8117-bc487ff1d41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 26.4M/26.4M [00:20<00:00, 1.26MB/s]\n",
      "100%|| 29.5k/29.5k [00:00<00:00, 98.4kB/s]\n",
      "100%|| 4.42M/4.42M [00:05<00:00, 786kB/s]\n",
      "100%|| 5.15k/5.15k [00:00<00:00, 7.92MB/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.FashionMNIST(\n",
    "    root = \"data\",\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "7248feed-f091-4db0-a441-6f8184b9197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.FashionMNIST(\n",
    "    root = \"data\",\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "aa78df25-6572-4f5c-ab13-f66926ba1134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset FashionMNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: ToTensor(),\n",
       " Dataset FashionMNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: data\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: ToTensor())"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "da20846d-476d-4cd9-9a44-48dc8a6228ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "63cebc03-4da9-41a8-8206-3d2397bab490",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, in_channels, out_dim):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Conv2d(in_channels, out_channels = 64, kernel_size = (3,3), stride = 1)\n",
    "        \n",
    "        self.layer2 = nn.Conv2d(64, out_channels = 32, kernel_size = (3,3), stride = 1)\n",
    "        \n",
    "        self.layer3 = nn.Conv2d(32, out_channels = 16, kernel_size = (3,3), stride = 1)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size = (2,2))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(16 * 11 * 11, out_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(self.relu(x))\n",
    "        x = self.layer3(self.relu(x))\n",
    "        x = self.max_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "2bce600c-dff4-4538-a732-e9d7491cfeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNModel(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "70b01046-c1ef-4fc7-ac12-68401f7f82ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "c32f7c08-7165-4fcf-82d2-fc667a36d54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "55601b33-db7f-431a-9e5b-eb2ca24dbd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size = 32, shuffle = True)\n",
    "test_dataloader = DataLoader(test_data, batch_size = 32, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d43e54-a10b-42a2-8d5a-28bef6c88a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    model.train()\n",
    "    for x,y in train_dataloader:\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        print(loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "99561d27-cd86-4dad-be1c-2334b39faa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "217d3300-2641-42e4-b121-1ed027bb5814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text data (features)\n",
    "texts = [\n",
    "    \"I love this product\",\n",
    "    \"This is the worst experience ever\",\n",
    "    \"Absolutely fantastic service\",\n",
    "    \"I am very disappointed\",\n",
    "    \"Great quality and fast delivery\",\n",
    "    \"Not worth the money\",\n",
    "    \"I am happy with the purchase\",\n",
    "    \"Terrible customer support\"\n",
    "]\n",
    "\n",
    "# Binary labels\n",
    "# 1 = Positive\n",
    "# 0 = Negative\n",
    "labels = [\n",
    "    1,  # I love this product\n",
    "    0,  # This is the worst experience ever\n",
    "    1,  # Absolutely fantastic service\n",
    "    0,  # I am very disappointed\n",
    "    1,  # Great quality and fast delivery\n",
    "    0,  # Not worth the money\n",
    "    1,  # I am happy with the purchase\n",
    "    0   # Terrible customer support\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "9988bdbf-b33a-400c-96f8-e90f562e992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "2ff0130a-faa0-421a-a06d-b54f1a962745",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextData(Dataset):\n",
    "\n",
    "    def __init__(self, data, labels, vocab_size = 50, sequence_length = 7):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.vocab_size = vocab_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vacabulary = self.get_vacabulary(vocab_size)\n",
    "\n",
    "    def get_vacabulary(self, vocab_size):\n",
    "        texts = \" \".join(self.data)\n",
    "        counters = Counter(texts.split(\" \"))\n",
    "        most_freq = counters.most_common(vocab_size)\n",
    "        vocab = {k[0]: i + 1 for i, k in enumerate(most_freq)}\n",
    "        vocab[\"UNK\"] = 0\n",
    "        return vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data[idx].split(\" \")\n",
    "        label = self.labels[idx]\n",
    "        text = [self.vacabulary.get(t) for t in text]\n",
    "        if len(text) < 7:\n",
    "            text += [0] * (7 - len(text))\n",
    "        else:\n",
    "            text = text[:7]\n",
    "\n",
    "        return torch.tensor(text), torch.tensor(label)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "4888bea1-b2ce-4fd3-ad56-c755067d1166",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TextData(texts, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "aa2481b0-1342-422d-978f-da180ffac3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(data, batch_size = 32, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "940d32e3-afa1-4225-b039-4db2162afd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 4, 5, 6, 0, 0, 0]), tensor(1))"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "21da9e84-206a-4c9c-8520-1b4df6539c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self,vocab_size = 50, embedding_dim=28, hidden_dim=32, output_dim=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings = vocab_size , embedding_dim= embedding_dim)\n",
    "        self.rnn = nn.RNN(input_size = embedding_dim, hidden_size = hidden_dim, num_layers = 2,batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x_out, hidden = self.rnn(x)\n",
    "        x = self.fc(hidden[-1])\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "8dd8157f-3ad9-4bb1-9df8-4553a98047ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "2741ea72-6a24-46bc-9fa2-653e7627465a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "4d1f946d-3392-4624-9b63-365846ab0a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a260f0a-6d25-4aa9-b527-cd4067baaf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    model.train()\n",
    "\n",
    "    for x, y in train_dataloader:\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316bfa1a-f8c8-48f0-9b15-bfc28258508a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45c458c-778b-4219-bec0-aa57e6ff4ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9af4b47-3722-40a3-90e2-9753ff558f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32145d1-de28-4970-933a-570bc58b9707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb2fd59-f01d-4b37-a1b4-d1956c5055e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56537f30-a614-4a26-804a-2dea38c71b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a449f03d-febf-48b2-a016-5ebcaa883ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e804ddb-8e74-4687-92c8-7e97f597a0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625ed5a3-1fb9-4274-b04c-f3aa269746c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18381c3e-ea9f-44cb-9366-b336fa5ef735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a632446a-ac27-41ef-b8c9-ad457606963b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "Python\n",
      "Python  \n",
      "  Python\n",
      "['apple', 'banana', 'orange']\n",
      "Hello World\n",
      "I like Python\n",
      "1\n",
      "5\n",
      "3\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "PYTHON\n",
      "python\n",
      "Python\n",
      "Python\n",
      "pYTHON\n"
     ]
    }
   ],
   "source": [
    "s = \"python.py\"\n",
    "print(s.startswith(\"py\"))  # True\n",
    "print(s.endswith(\".py\"))   # True\n",
    "\n",
    "\n",
    "s = \"  Python  \"\n",
    "print(s.strip())   # Python\n",
    "print(s.lstrip())  # Python  \n",
    "print(s.rstrip())  #   Python\n",
    "\n",
    "s = \"apple,banana,orange\"\n",
    "print(s.split(\",\"))    # ['apple', 'banana', 'orange']\n",
    "\n",
    "words = [\"Hello\", \"World\"]\n",
    "print(\" \".join(words)) # Hello World\n",
    "\n",
    "\n",
    "s = \"I like Java\"\n",
    "print(s.replace(\"Java\", \"Python\"))  # I like Python\n",
    "\n",
    "\n",
    "s = \"banana\"\n",
    "print(s.find(\"a\"))     # 1\n",
    "print(s.rfind(\"a\"))    # 5\n",
    "print(s.count(\"a\"))    # 3\n",
    "\n",
    "\n",
    "s = \"Python123\"\n",
    "print(s.isalpha())   # False\n",
    "print(s.isdigit())   # False\n",
    "print(s.isalnum())   # True\n",
    "print(s.islower())   # False\n",
    "print(s.isupper())   # False\n",
    "print(s.isspace())   # False\n",
    "\n",
    "\n",
    "s = \"Python\"\n",
    "print(s.upper())     # PYTHON\n",
    "print(s.lower())     # python\n",
    "print(s.title())     # Python\n",
    "print(s.capitalize())# Python\n",
    "print(s.swapcase())  # pYTHON\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "a49d7e0e-85dc-4433-8577-7e5892478d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "b906d40b-8883-442a-a736-b39ecb6c0cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d9caf0b-128d-4488-b4c0-201ba55f2119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ceaa5f9-c268-4328-b2f0-c9aa2308b260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"deepseek-ai/DeepSeek-R1-0528\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False,\n",
    "    repetition_penalty=1.03,\n",
    "    provider=\"auto\",  # let Hugging Face choose the best provider for you\n",
    ")\n",
    "\n",
    "chat_model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0de040e-65f3-47b8-9f66-d5bf9a908572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f1343a4-4bd5-4e13-a9bc-fb4ec7686b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def retrieve_info(query: str):\n",
    "    \"\"\"Retrieve information from the vector database\n",
    "    Args:\n",
    "        Query(str): Qeury for which you want to retrive\n",
    "    \"\"\"\n",
    "    return \"NO infomration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7310744-8b0e-47a6-adb5-900d26c0a09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = chat_model.bind_tools([retrieve_info])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed67bac0-9a1e-4fec-ac45-1488be3e9965",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = llm.invoke(\"give the info about the latest sales data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b230042-3164-4652-8d91-8b20a3ead930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'latest sales data'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.tool_calls[0].get(\"args\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2be76eb-2715-4952-b817-55ddb47fe5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The medieval period brought significant cultural transformations with the arrival of Islamic rulers, leading to the Delhi Sultanate and later the Mughal Empire. The Mughals left a lasting legacy in architecture, administration, and art, epitomized by monuments like the Taj Mahal. European trading companies, particularly the British East India Company, gradually gained power, eventually leading to nearly two centuries of British colonial rule. Indias struggle for independence, marked by movements led by figures like Mahatma Gandhi and Jawaharlal Nehru, culminated in freedom in 1947.\n",
      "\n",
      "Today, Indias history is celebrated not only through its monuments and literature but also through its diverse cultural traditions, languages, and philosophies, reflecting a civilization that has continuously evolved while preserving its ancient heritage.\n",
      "\n",
      "---\n",
      "\n",
      "If you want, I can also write a **shorter, more concise version** suitable for exams or quick reading. Do you want me to do that?\n",
      "Heres a well-rounded passage on Indian history:\n",
      "\n",
      "---\n",
      "\n",
      "India has one of the worlds oldest and richest histories, stretching back over 5,000 years. The Indus Valley Civilization, flourishing around 2500 BCE in present-day Pakistan and northwest India, was one of the earliest urban societies, known for its advanced city planning, trade networks, and script. Following this, the Vedic period laid the foundations of Hindu culture, religion, and society. Over centuries, India saw the rise and fall of many empires, including the Maurya Empire under Emperor Ashoka, who embraced Buddhism and promoted non-violence, and the Gupta Empire, which is often called the Golden Age due to its remarkable achievements in science, art, and literature.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "\n",
    "\n",
    "# load one or more text files\n",
    "loader = TextLoader(\"your_text.txt\", encoding = \"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "# split larger texts into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name = \"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "faiss_db = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "\n",
    "query = \"What is the key idea?\"\n",
    "results = faiss_db.similarity_search(query, k=5)\n",
    "for doc in results:\n",
    "    print(doc.page_content)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "485a337b-a3dd-49cb-bbb5-8d250b85ee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "docs = [\n",
    "    Document(page_content=\"Text of doc1\", metadata={\"source\": \"doc1.txt\"}),\n",
    "    Document(page_content=\"Text of doc2\", metadata={\"source\": \"doc2.txt\"}),\n",
    "]\n",
    "faiss_db = FAISS.from_documents(docs, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abf403a-192f-4729-9db0-7c85ced7f17b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cd64e7-ce96-4650-9b76-5e8ed0145c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
